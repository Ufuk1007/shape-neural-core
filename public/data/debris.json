[
  {
    "id": "latent_sculptor_3d_gan_release",
    "category": "STR_ART",
    "headline": "Latent Sculptor lets artists 'carve' 3D forms from text and sketches",
    "summary": "A new research prototype called Latent Sculptor combines a 3D-aware generative model with sketch and text conditioning, allowing artists to iteratively 'carve' and refine complex 3D shapes in real time. This matters for design because it turns 3D modeling into a conversational, gestural process instead of a purely technical one, making spatial exploration more like drawing than CAD.",
    "url": "https://research-lab.example.org/latent-sculptor-3d",
    "relevance": 96
  },
  {
    "id": "video_stylebrush_temporal_painting",
    "category": "STR_ART",
    "headline": "Temporal StyleBrush enables frame-consistent AI painting in video",
    "summary": "Temporal StyleBrush is a new technique that applies painterly styles to video while preserving temporal coherence, so strokes feel hand-made rather than 'boiling' frame to frame. For motion designers and VJs, this offers a controllable way to blend illustration, animation, and live-action without the jitter that has plagued most style-transfer pipelines.",
    "url": "https://arxiv.org/abs/2512.03102",
    "relevance": 92
  },
  {
    "id": "design_copilot_multimodal_ux_spec",
    "category": "CX_UX",
    "headline": "Multimodal 'Design Copilot' turns whiteboard photos into UX specs",
    "summary": "A new UX assistant tool parses whiteboard sketches, sticky notes, and verbal recordings from workshops, converting them into structured user flows and component inventories. This shifts early-stage UX from manual documentation to AI-supported synthesis, freeing designers to focus on intent and interaction rather than diagram cleanup.",
    "url": "https://uxlab.example.com/blog/design-copilot-workshop-to-wireframes",
    "relevance": 94
  },
  {
    "id": "adaptive_persona_engine_llm_testing",
    "category": "CX_UX",
    "headline": "Adaptive persona engine uses LLMs for live UX scenario testing",
    "summary": "An experimental 'adaptive persona engine' uses LLM agents with calibrated traits (age, tech literacy, cognitive load thresholds) to simulate realistic user sessions on prototypes. Designers can run quick what-if tests on flows, accessibility, and edge cases before recruiting real participants, making UX research more iterative without replacing human testing.",
    "url": "https://medium.com/@uxai/adaptive-persona-engine",
    "relevance": 90
  },
  {
    "id": "procedural_brand_system_diffusion",
    "category": "STR_ART",
    "headline": "Procedural brand system generator builds living identities from prompts",
    "summary": "A new branding prototype uses diffusion models plus layout constraints to generate entire identity systems—logos, grids, color systems, and motion behaviors—from a short narrative brief. Rather than spitting out one logo, it gives art directors a parametric space to explore, critique, and refine, reframing identity design as system steering instead of one-off artifact creation.",
    "url": "https://brandlab.example.net/procedural-identity-ai",
    "relevance": 93
  },
  {
    "id": "suno_v6_stem_control_release",
    "category": "SONIC",
    "headline": "AI music engine adds fine-grained stem control for structure and mix",
    "summary": "A new version of a popular AI music model introduces explicit control over stems (drums, bass, vocals, FX) and song sections (intro, verse, drop, bridge) through natural language. This gives producers a way to direct arrangement and mix like they would with a human collaborator, instead of fighting against opaque, end-to-end generations.",
    "url": "https://audioai.example.com/blog/structured-stem-control",
    "relevance": 95
  },
  {
    "id": "neural_foley_physical_interaction",
    "category": "SONIC",
    "headline": "Neural Foley maps physical gestures to cinematic soundscapes",
    "summary": "Neural Foley is a performance system that uses body tracking and contact microphones to drive a generative audio engine, synthesizing context-aware Foley and ambience in real time. For sound designers and installation artists, it turns physical interaction into a material for live sound world-building, blurring lines between instrument, environment, and score.",
    "url": "https://chi-sound.example.org/2025/neural-foley",
    "relevance": 91
  },
  {
    "id": "voice_chimera_morphing_identities",
    "category": "SONIC",
    "headline": "Voice Chimera enables fluid identity morphing in spoken dialogue",
    "summary": "Voice Chimera is a new model that can continuously morph between multiple vocal identities mid-sentence based on emotional or narrative cues. Beyond novelty, this opens up design space for interactive audio fiction, characterful agents, and accessibility tools that can subtly adapt voice qualities to listener comfort or context.",
    "url": "https://speechlab.example.edu/voice-chimera",
    "relevance": 88
  },
  {
    "id": "affective_prototyping_llm_emotion",
    "category": "CX_UX",
    "headline": "Affective prototyping toolkit tests emotional tone of AI interfaces",
    "summary": "A new design research toolkit lets teams script multi-turn conversations with LLM-based agents while tracking perceived emotion, trust, and cognitive load in participants. It matters because it treats emotional experience as a first-class design parameter for AI interactions, offering repeatable ways to tune tone, pacing, and handoff between human and machine.",
    "url": "https://uxresearch.example.com/affective-ai-prototyping",
    "relevance": 89
  },
  {
    "id": "latent_walks_museum_installation",
    "category": "STR_ART",
    "headline": "Museum installation uses model 'latent walks' as a new visual medium",
    "summary": "A newly opened exhibition centers on 'latent walks'—continuous traversals through a generative model's feature space—projected as evolving visual tapestries with synchronized sound. It reframes AI not as an image generator but as a dynamic landscape to be navigated, inviting curators and artists to treat models themselves as sites of exploration.",
    "url": "https://museum.example.org/exhibitions/latent-walks",
    "relevance": 87
  },
  {
    "id": "nonhuman_authorship_symposium",
    "category": "META",
    "headline": "Symposium questions authorship in 'nonhuman co-composed' artworks",
    "summary": "A philosophy and art theory symposium brought together legal scholars, artists, and computational theorists to debate whether highly autonomous generative systems qualify as 'co-authors'. The discussions push beyond copyright toward design ethics, asking how interface choices, dataset curation, and model affordances distribute agency in creative practice.",
    "url": "https://theoryofai.example.com/events/nonhuman-authorship-2025",
    "relevance": 92
  },
  {
    "id": "contingent_creativity_preprint",
    "category": "META",
    "headline": "New paper argues AI creativity is 'contingent' not 'derivative'",
    "summary": "A recent preprint in philosophy of mind proposes that AI systems exhibit 'contingent creativity'—novelty constrained by training contingencies—rather than simple remix. Designers can use this framing to think less about human vs machine originality and more about how dataset boundaries and interface feedback loops channel what AI can invent.",
    "url": "https://arxiv.org/abs/2512.02840",
    "relevance": 90
  },
  {
    "id": "ai_as_medium_design_critique",
    "category": "META",
    "headline": "Essay reframes AI not as tool but as a design medium with biases",
    "summary": "A long-form essay by a critical designer argues that AI systems should be treated like new materials—akin to concrete or photography—each with affordances, constraints, and embedded politics. This lens helps interaction and visual designers move beyond 'feature lists' to consider what kinds of forms, narratives, and exclusions each model tends to produce.",
    "url": "https://criticaldesign.example.net/ai-as-medium",
    "relevance": 93
  },
  {
    "id": "accessibility_first_agent_ui",
    "category": "CX_UX",
    "headline": "Accessibility-first AI agent UI adapts dynamically to impairments",
    "summary": "A new agent interface prototype auto-adjusts typography, contrast, interaction density, and modality based on inferred or declared impairments such as low vision, dyslexia, or motor limitations. It uses AI both to detect friction points in real time and to propose alternate interaction paths, pointing toward more inclusive defaults for AI-native products.",
    "url": "https://a11yux.example.org/blog/adaptive-agent-ui",
    "relevance": 91
  },
  {
    "id": "bio_feedback_driven_soundscapes",
    "category": "SONIC",
    "headline": "Biofeedback-driven AI soundscapes respond to audience nervous systems",
    "summary": "An experimental performance platform takes live heart rate and GSR data from audience members to shape generative drones, rhythms, and spatialization. Artists can treat the crowd's collective nervous system as an input, crafting responsive sound environments for mindfulness, horror, or club contexts that literally 'play' the listeners.",
    "url": "https://sonicarts.example.com/projects/biofeedback-scapes",
    "relevance": 89
  },
  {
    "id": "multimodal_prompt_grammar_for_art",
    "category": "STR_ART",
    "headline": "Multimodal prompt 'grammar' gives designers precise control over models",
    "summary": "A design research group published a 'prompt grammar' that mixes text, sketches, example images, and semantic sliders (e.g., abstraction, density, legibility) into a unified notation. This lets teams specify visual intent more systematically across tools and models, turning prompt craft from folk wisdom into a sharable, teachable design language.",
    "url": "https://designsystems.example.org/multimodal-prompt-grammar",
    "relevance": 94
  },
  {
    "id": "cooperative_agents_for_game_level_design",
    "category": "STR_ART",
    "headline": "Cooperative AI agents co-design game levels with human constraints",
    "summary": "A new game design workflow uses multiple specialized AI agents—one for pacing, one for aesthetics, one for difficulty curves—that negotiate with each other and the human designer in real time. Rather than auto-generating levels, the system supports a dialogic process where designers articulate constraints and see how agents reinterpret them structurally and visually.",
    "url": "https://gamedesign.ai-lab.example.com/cooperative-level-agents",
    "relevance": 88
  },
  {
    "id": "poetics_of_prompting_online_project",
    "category": "META",
    "headline": "Online project documents the 'poetics of prompting' as creative writing",
    "summary": "A collaborative web project treats prompts themselves as literary artifacts, curating side-by-side pairs of prompts and outputs annotated by writers, artists, and theorists. It foregrounds how much of AI art is authored at the level of language and interaction design, inviting practitioners to see prompt craft as a site of style, rhetoric, and ideology.",
    "url": "https://poeticprompting.example.art",
    "relevance": 86
  }
]